{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRAX4aF4q39I",
        "outputId": "b466a6d6-5fbf-4f81-f1e1-9382df2ec4dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "from nltk.corpus import gutenberg\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VcQtZUe4rLBg"
      },
      "outputs": [],
      "source": [
        "data = gutenberg.raw('shakespeare-hamlet.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LbvVFkworssL"
      },
      "outputs": [],
      "source": [
        "with open('hamlet.txt', 'w') as file:\n",
        "  file.write(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SBErdjdftyNt"
      },
      "outputs": [],
      "source": [
        "with open('hamlet.txt', 'r') as file:\n",
        "  text = file.read().lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "464DO7x7yCBl"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccbg1aeEyT4O",
        "outputId": "b302f2f4-3f2a-4496-92fd-613ea9880f55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4818"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_words = len(tokenizer.word_index) + 1\n",
        "total_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qX7p48pRyaVS"
      },
      "outputs": [],
      "source": [
        "input_sequences = []\n",
        "for line in text.split('\\n'):\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_sequences = token_list[: i + 1]\n",
        "    input_sequences.append(n_gram_sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Xu0c4grN6Jtu"
      },
      "outputs": [],
      "source": [
        "max_sequence_len = max([len(x) for x in input_sequences])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTCP8DAj97va",
        "outputId": "e7207fd6-2f62-408a-9de8-c9de13f1c63d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_sequence_len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_1Zh0Hi99Cm",
        "outputId": "964c6703-9dfc-4a18-eaf5-46d0ac3f3ced"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0,    1,  687],\n",
              "       [   0,    0,    0, ...,    1,  687,    4],\n",
              "       [   0,    0,    0, ...,  687,    4,   45],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    4,   45, 1047],\n",
              "       [   0,    0,    0, ...,   45, 1047,    4],\n",
              "       [   0,    0,    0, ..., 1047,    4,  193]], dtype=int32)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen = max_sequence_len, padding = 'pre'))\n",
        "input_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OmGlVqLK-UdP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "X, y = input_sequences[:, : -1], input_sequences[:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RxokxAEk-64R"
      },
      "outputs": [],
      "source": [
        "y = tf.keras.utils.to_categorical(y, num_classes = total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CdhuPnbX_kYQ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "IqEcofCH_y1B"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kZtckIOZAPVw"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100))\n",
        "model.add(LSTM(150, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "RzPEpKvMBCZL",
        "outputId": "98a56af3-2ced-44b2-c44a-f07f436e4a98"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oohUsqWKBXvQ",
        "outputId": "298a176c-d185-4bdf-aba8-1659e74c405d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 12ms/step - accuracy: 0.0275 - loss: 7.1494 - val_accuracy: 0.0356 - val_loss: 6.6996\n",
            "Epoch 2/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.0352 - loss: 6.4404 - val_accuracy: 0.0455 - val_loss: 6.7856\n",
            "Epoch 3/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.0420 - loss: 6.3426 - val_accuracy: 0.0519 - val_loss: 6.8522\n",
            "Epoch 4/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.0496 - loss: 6.1844 - val_accuracy: 0.0517 - val_loss: 6.8818\n",
            "Epoch 5/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - accuracy: 0.0526 - loss: 6.0718 - val_accuracy: 0.0542 - val_loss: 6.8969\n",
            "Epoch 6/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.0643 - loss: 5.9079 - val_accuracy: 0.0591 - val_loss: 6.9044\n",
            "Epoch 7/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.0681 - loss: 5.7669 - val_accuracy: 0.0629 - val_loss: 6.9680\n",
            "Epoch 8/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.0774 - loss: 5.6356 - val_accuracy: 0.0705 - val_loss: 7.0289\n",
            "Epoch 9/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.0871 - loss: 5.4613 - val_accuracy: 0.0727 - val_loss: 7.0559\n",
            "Epoch 10/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.0996 - loss: 5.3050 - val_accuracy: 0.0709 - val_loss: 7.1633\n",
            "Epoch 11/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.1028 - loss: 5.1897 - val_accuracy: 0.0729 - val_loss: 7.2490\n",
            "Epoch 12/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.1063 - loss: 5.0651 - val_accuracy: 0.0699 - val_loss: 7.3237\n",
            "Epoch 13/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12ms/step - accuracy: 0.1147 - loss: 4.9366 - val_accuracy: 0.0705 - val_loss: 7.4564\n",
            "Epoch 14/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.1207 - loss: 4.8069 - val_accuracy: 0.0701 - val_loss: 7.5988\n",
            "Epoch 15/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.1294 - loss: 4.6382 - val_accuracy: 0.0707 - val_loss: 7.7150\n",
            "Epoch 16/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.1253 - loss: 4.5788 - val_accuracy: 0.0676 - val_loss: 7.8355\n",
            "Epoch 17/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.1385 - loss: 4.4418 - val_accuracy: 0.0690 - val_loss: 7.9682\n",
            "Epoch 18/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.1461 - loss: 4.3464 - val_accuracy: 0.0696 - val_loss: 8.0997\n",
            "Epoch 19/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.1564 - loss: 4.2128 - val_accuracy: 0.0697 - val_loss: 8.2562\n",
            "Epoch 20/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.1739 - loss: 4.1231 - val_accuracy: 0.0684 - val_loss: 8.3988\n",
            "Epoch 21/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.1903 - loss: 4.0214 - val_accuracy: 0.0645 - val_loss: 8.5407\n",
            "Epoch 22/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.2038 - loss: 3.9105 - val_accuracy: 0.0666 - val_loss: 8.6906\n",
            "Epoch 23/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.2150 - loss: 3.8157 - val_accuracy: 0.0639 - val_loss: 8.8328\n",
            "Epoch 24/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.2316 - loss: 3.7541 - val_accuracy: 0.0620 - val_loss: 8.9602\n",
            "Epoch 25/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.2471 - loss: 3.6430 - val_accuracy: 0.0641 - val_loss: 9.0681\n",
            "Epoch 26/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.2600 - loss: 3.5920 - val_accuracy: 0.0637 - val_loss: 9.1856\n",
            "Epoch 27/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.2680 - loss: 3.5088 - val_accuracy: 0.0616 - val_loss: 9.3227\n",
            "Epoch 28/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.2848 - loss: 3.4484 - val_accuracy: 0.0604 - val_loss: 9.4475\n",
            "Epoch 29/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.2940 - loss: 3.3759 - val_accuracy: 0.0583 - val_loss: 9.5475\n",
            "Epoch 30/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.2994 - loss: 3.3262 - val_accuracy: 0.0577 - val_loss: 9.6779\n",
            "Epoch 31/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.3217 - loss: 3.2541 - val_accuracy: 0.0595 - val_loss: 9.7769\n",
            "Epoch 32/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.3297 - loss: 3.1815 - val_accuracy: 0.0577 - val_loss: 9.8648\n",
            "Epoch 33/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.3345 - loss: 3.1543 - val_accuracy: 0.0595 - val_loss: 10.0194\n",
            "Epoch 34/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.3477 - loss: 3.0889 - val_accuracy: 0.0579 - val_loss: 10.0768\n",
            "Epoch 35/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.3571 - loss: 3.0299 - val_accuracy: 0.0552 - val_loss: 10.1817\n",
            "Epoch 36/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.3616 - loss: 2.9946 - val_accuracy: 0.0554 - val_loss: 10.2830\n",
            "Epoch 37/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.3756 - loss: 2.9297 - val_accuracy: 0.0561 - val_loss: 10.3705\n",
            "Epoch 38/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.3791 - loss: 2.9073 - val_accuracy: 0.0548 - val_loss: 10.4332\n",
            "Epoch 39/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.3856 - loss: 2.8653 - val_accuracy: 0.0542 - val_loss: 10.5261\n",
            "Epoch 40/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.3978 - loss: 2.8016 - val_accuracy: 0.0542 - val_loss: 10.6066\n",
            "Epoch 41/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.4028 - loss: 2.7598 - val_accuracy: 0.0540 - val_loss: 10.6706\n",
            "Epoch 42/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.4083 - loss: 2.7312 - val_accuracy: 0.0554 - val_loss: 10.7194\n",
            "Epoch 43/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - accuracy: 0.4225 - loss: 2.6859 - val_accuracy: 0.0550 - val_loss: 10.8376\n",
            "Epoch 44/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.4260 - loss: 2.6587 - val_accuracy: 0.0556 - val_loss: 10.9413\n",
            "Epoch 45/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.4318 - loss: 2.6183 - val_accuracy: 0.0515 - val_loss: 10.9790\n",
            "Epoch 46/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.4441 - loss: 2.5598 - val_accuracy: 0.0511 - val_loss: 11.0641\n",
            "Epoch 47/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4451 - loss: 2.5437 - val_accuracy: 0.0515 - val_loss: 11.1422\n",
            "Epoch 48/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.4505 - loss: 2.5184 - val_accuracy: 0.0532 - val_loss: 11.2169\n",
            "Epoch 49/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.4478 - loss: 2.4927 - val_accuracy: 0.0560 - val_loss: 11.2889\n",
            "Epoch 50/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.4679 - loss: 2.4337 - val_accuracy: 0.0542 - val_loss: 11.3482\n",
            "Epoch 51/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.4650 - loss: 2.4279 - val_accuracy: 0.0511 - val_loss: 11.4014\n",
            "Epoch 52/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.4778 - loss: 2.3801 - val_accuracy: 0.0550 - val_loss: 11.4738\n",
            "Epoch 53/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4848 - loss: 2.3525 - val_accuracy: 0.0528 - val_loss: 11.5725\n",
            "Epoch 54/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.4946 - loss: 2.2847 - val_accuracy: 0.0513 - val_loss: 11.6102\n",
            "Epoch 55/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.4895 - loss: 2.3097 - val_accuracy: 0.0534 - val_loss: 11.6912\n",
            "Epoch 56/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.5032 - loss: 2.2398 - val_accuracy: 0.0536 - val_loss: 11.7479\n",
            "Epoch 57/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5043 - loss: 2.2333 - val_accuracy: 0.0532 - val_loss: 11.8239\n",
            "Epoch 58/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.5040 - loss: 2.2194 - val_accuracy: 0.0525 - val_loss: 11.8686\n",
            "Epoch 59/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5222 - loss: 2.1636 - val_accuracy: 0.0534 - val_loss: 11.9080\n",
            "Epoch 60/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5285 - loss: 2.1210 - val_accuracy: 0.0542 - val_loss: 11.9780\n",
            "Epoch 61/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.5266 - loss: 2.1221 - val_accuracy: 0.0550 - val_loss: 12.0557\n",
            "Epoch 62/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.5332 - loss: 2.0972 - val_accuracy: 0.0528 - val_loss: 12.1261\n",
            "Epoch 63/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5373 - loss: 2.0782 - val_accuracy: 0.0527 - val_loss: 12.1405\n",
            "Epoch 64/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.5457 - loss: 2.0339 - val_accuracy: 0.0525 - val_loss: 12.2017\n",
            "Epoch 65/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5402 - loss: 2.0314 - val_accuracy: 0.0556 - val_loss: 12.3171\n",
            "Epoch 66/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5609 - loss: 1.9795 - val_accuracy: 0.0511 - val_loss: 12.3375\n",
            "Epoch 67/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5541 - loss: 1.9853 - val_accuracy: 0.0515 - val_loss: 12.3839\n",
            "Epoch 68/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.5621 - loss: 1.9361 - val_accuracy: 0.0519 - val_loss: 12.4733\n",
            "Epoch 69/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - accuracy: 0.5668 - loss: 1.9189 - val_accuracy: 0.0505 - val_loss: 12.5155\n",
            "Epoch 70/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.5663 - loss: 1.9324 - val_accuracy: 0.0525 - val_loss: 12.5959\n",
            "Epoch 71/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.5734 - loss: 1.9040 - val_accuracy: 0.0501 - val_loss: 12.6000\n",
            "Epoch 72/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5832 - loss: 1.8453 - val_accuracy: 0.0534 - val_loss: 12.6928\n",
            "Epoch 73/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5808 - loss: 1.8717 - val_accuracy: 0.0521 - val_loss: 12.7721\n",
            "Epoch 74/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.5884 - loss: 1.8280 - val_accuracy: 0.0523 - val_loss: 12.7907\n",
            "Epoch 75/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.5907 - loss: 1.8093 - val_accuracy: 0.0554 - val_loss: 12.8466\n",
            "Epoch 76/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.5971 - loss: 1.7743 - val_accuracy: 0.0534 - val_loss: 12.8836\n",
            "Epoch 77/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.6036 - loss: 1.7584 - val_accuracy: 0.0505 - val_loss: 12.9511\n",
            "Epoch 78/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.6040 - loss: 1.7446 - val_accuracy: 0.0511 - val_loss: 13.0071\n",
            "Epoch 79/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.6102 - loss: 1.7181 - val_accuracy: 0.0499 - val_loss: 13.0171\n",
            "Epoch 80/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.6097 - loss: 1.7137 - val_accuracy: 0.0505 - val_loss: 13.0713\n",
            "Epoch 81/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6240 - loss: 1.6774 - val_accuracy: 0.0527 - val_loss: 13.1582\n",
            "Epoch 82/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.6182 - loss: 1.6879 - val_accuracy: 0.0542 - val_loss: 13.1882\n",
            "Epoch 83/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.6232 - loss: 1.6477 - val_accuracy: 0.0517 - val_loss: 13.2558\n",
            "Epoch 84/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6244 - loss: 1.6505 - val_accuracy: 0.0527 - val_loss: 13.2619\n",
            "Epoch 85/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.6270 - loss: 1.6251 - val_accuracy: 0.0503 - val_loss: 13.3365\n",
            "Epoch 86/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - accuracy: 0.6345 - loss: 1.6021 - val_accuracy: 0.0532 - val_loss: 13.3512\n",
            "Epoch 87/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.6489 - loss: 1.5822 - val_accuracy: 0.0499 - val_loss: 13.4365\n",
            "Epoch 88/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.6369 - loss: 1.5836 - val_accuracy: 0.0534 - val_loss: 13.4453\n",
            "Epoch 89/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.6404 - loss: 1.5636 - val_accuracy: 0.0530 - val_loss: 13.5082\n",
            "Epoch 90/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.6496 - loss: 1.5409 - val_accuracy: 0.0511 - val_loss: 13.5445\n",
            "Epoch 91/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.6468 - loss: 1.5456 - val_accuracy: 0.0511 - val_loss: 13.6192\n",
            "Epoch 92/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.6541 - loss: 1.5106 - val_accuracy: 0.0501 - val_loss: 13.6862\n",
            "Epoch 93/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.6593 - loss: 1.4795 - val_accuracy: 0.0517 - val_loss: 13.6803\n",
            "Epoch 94/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6618 - loss: 1.4796 - val_accuracy: 0.0503 - val_loss: 13.7472\n",
            "Epoch 95/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.6615 - loss: 1.4709 - val_accuracy: 0.0511 - val_loss: 13.8088\n",
            "Epoch 96/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.6681 - loss: 1.4582 - val_accuracy: 0.0484 - val_loss: 13.8208\n",
            "Epoch 97/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.6724 - loss: 1.4419 - val_accuracy: 0.0474 - val_loss: 13.8618\n",
            "Epoch 98/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.6661 - loss: 1.4369 - val_accuracy: 0.0517 - val_loss: 13.9304\n",
            "Epoch 99/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6710 - loss: 1.4403 - val_accuracy: 0.0501 - val_loss: 13.9821\n",
            "Epoch 100/100\n",
            "\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6776 - loss: 1.4021 - val_accuracy: 0.0488 - val_loss: 13.9968\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs = 100,\n",
        "    validation_data = (X_test, y_test),\n",
        "    verbose = 1\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MDChl2EnGnJ2"
      },
      "outputs": [],
      "source": [
        "model.save('next_word_lstm.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nAtg6sQNJugo"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "  pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "x949K_KoH4HQ"
      },
      "outputs": [],
      "source": [
        "def predict_next_word(model, tokenizer, text, max_sequence_len):\n",
        "  token_list = tokenizer.texts_to_sequences([text])[0]\n",
        "  if len(token_list) >= max_sequence_len:\n",
        "    token_list = token_list[-(max_sequence_len - 1):]\n",
        "  token_list = pad_sequences([token_list], maxlen = max_sequence_len - 1, padding = 'pre')\n",
        "  predicted = model.predict(token_list, verbose = 0)\n",
        "  predicted_word_index = np.argmax(predicted, axis = 1)\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted_word_index:\n",
        "      return word\n",
        "  return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxXLbYaQJBhR",
        "outputId": "b8e75bae-5fbb-4eab-fd14-11282613cb1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input text: let beleefe take hold of\n",
            "Next word: him\n"
          ]
        }
      ],
      "source": [
        "input_text = \"let beleefe take hold of\"\n",
        "print(f\"Input text: {input_text}\")\n",
        "max_sequence_len = model.input_shape[1] + 1\n",
        "next_word = predict_next_word(model, tokenizer, input_text, max_sequence_len)\n",
        "print(f\"Next word: {next_word}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb6v1LILJhdo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
